{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex, subprocess, time\n",
    "import runconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = runconfig.get_config_dict()\n",
    "dataset_name = config_dict['dataset_name']\n",
    "outlier_fraction = config_dict['outlier_fraction']\n",
    "num_clients_per_class = config_dict['num_clients_per_class']\n",
    "association_threshold = config_dict['association_threshold']\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "\n",
    "l_ideal = []\n",
    "for p1 in range(num_class):\n",
    "    l2 = []\n",
    "    for p2 in range(num_clients_per_class):  \n",
    "        l2.append(str(p1)+\"_\"+str(p2))\n",
    "    l_ideal.append(l2)\n",
    "l_ideal\n",
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_file_name = dataset_name + str(num_clients_per_class) + '_communities.txt'\n",
    "with open('data/'+communities_file_name) as file:\n",
    "    lines = file.readlines()\n",
    "    l_communities = [sorted(line.strip().replace(' ', '').split(',')) for line in lines]\n",
    "\n",
    "for i in l_communities:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "liss = l_communities; out_fold = 'communities' \n",
    "liss = l_ideal; out_fold = 'ideal' \n",
    "\n",
    "address = 5000 # is actually a port. Server and clients of the same group have the same port\n",
    "for num,i in enumerate(liss[0:]):\n",
    "    print(str(i))\n",
    "    ll = ['./fed_start.sh', dataset_name, str(address+num), str(num_clients_per_class), out_fold] + i\n",
    "    as_string = \" \".join(ll)\n",
    "    subprocess.check_call(as_string, shell=True)\n",
    "    #subprocess.Popen(as_string, shell=True)\n",
    "    #time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_name = 'mnist'\n",
    "#dataset_name = 'fashion_mnist'\n",
    "#num_clients_per_class = 18\n",
    "\n",
    "\n",
    "pth = 'out'+str(num_clients_per_class)+'/'\n",
    "#pth = 'out9/'\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(pth+\"output_local/\"+dataset_name+\"/*.csv\")\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "for f in files:\n",
    "    csv = pd.read_csv(f, index_col=[0])\n",
    "    df1 = pd.concat([df1,csv])\n",
    "    df1 = df1.sort_values('dataset')\n",
    "df1 = df1.add_suffix('_local').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(pth+\"output_communities/\"+dataset_name+\"/*.csv\")\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "for f in files:\n",
    "    csv = pd.read_csv(f,index_col=[0])\n",
    "    df2 = pd.concat([df2,csv])\n",
    "    df2 = df2.sort_values('dataset')\n",
    "df2 = df2.add_suffix('_clust').reset_index(drop=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(pth+\"output_ideal/\"+dataset_name+\"/*.csv\")\n",
    "\n",
    "df3 = pd.DataFrame()\n",
    "for f in files:\n",
    "    csv = pd.read_csv(f,index_col=[0])\n",
    "    df3 = pd.concat([df3,csv])\n",
    "    df3 = df3.sort_values('dataset').reset_index(drop=True)\n",
    "df3 = df3.add_suffix('_ideal').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1,df2,df3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'f1in'\n",
    "metric = 'f1out'\n",
    "#metric = 'acc'\n",
    "metric = 'aucroc'\n",
    "pd.concat([df1,df2,df3],axis=1)\n",
    "pd.concat([df1,df2,df3],axis=1)[[metric+'_local',metric+'_clust',metric+'_ideal']].reset_index(drop=True).style.highlight_max(color = 'lightgreen', axis = 1)\n",
    "pd.concat([df1,df2,df3],axis=1)[[metric+'_local',metric+'_clust',metric+'_ideal']].reset_index(drop=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1['inlier'] = df2['dataset_ideal'].str.split('_', 1, expand=True)[0]\n",
    "#df2['inlier'] = df2['dataset_ideal'].str.split('_', 1, expand=True)[0] # aggiungo la colonna inlier solo a 1\n",
    "df3['inlier'] = df3['dataset_ideal'].str.split('_', 1, expand=True)[0]\n",
    "pd.concat([df1,df2,df3],axis=1)[['inlier',metric+'_local',metric+'_clust',metric+'_ideal']].groupby('inlier').mean().style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "593665181263e4e28b0282309c1fb63b3ae40b89f9103e442a55dea02677e3c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
